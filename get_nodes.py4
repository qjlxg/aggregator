#内容全都获取到
import requests
import re
import os
import base64
import yaml
import json

# 定义支持的节点协议
PROTOCOLS = [
    'vless://', 'vmess://', 'trojan://', 'ss://', 'ssr://',
    'wireguard://', 'grpc://', 'snell://', 'hysteria://',
    'hysteria2://', 'tuic://', 'juicity://'
]

def extract_nodes_from_content(content, content_type='plain', source_url="Unknown"):
    """根据内容类型提取节点信息"""
    nodes = set()
    if not content:
        print(f"DEBUG: [{source_url}] 内容为空，无法提取节点 (类型: {content_type})")
        return list(nodes)

    if content_type == 'base64':
        try:
            # Pad base64 string if necessary
            missing_padding = len(content) % 4
            if missing_padding:
                content += '=' * (4 - missing_padding)
            decoded_content = base64.b64decode(content).decode('utf-8', errors='ignore')
            for line in decoded_content.splitlines():
                line = line.strip()
                if any(line.startswith(proto) for proto in PROTOCOLS):
                    nodes.add(line)
            print(f"DEBUG: [{source_url}] Base64解码后提取到 {len(nodes)} 个节点")
        except Exception as e:
            print(f"错误: [{source_url}] Base64解码失败: {e}. 原始内容前100字符: {content[:100]}")
    elif content_type == 'yaml':
        try:
            data = yaml.safe_load(content)
            if isinstance(data, dict) and 'proxies' in data and isinstance(data['proxies'], list):
                print(f"DEBUG: [{source_url}] YAML解析到 {len(data['proxies'])} 个代理")
                for i, proxy in enumerate(data['proxies']):
                    if not isinstance(proxy, dict):
                        print(f"警告: [{source_url}] YAML proxies列表中第 {i+1} 项不是字典格式, 跳过。")
                        continue
                    node_type = proxy.get('type')
                    # print(f"DEBUG: [{source_url}] 处理YAML代理类型: {node_type}") # 可以取消注释以获得更详细日志
                    try:
                        if node_type == 'vmess':
                            vmess_dict = {
                                "v": "2", "ps": proxy.get('name', 'unnamed'), "add": proxy.get('server'),
                                "port": proxy.get('port'), "id": proxy.get('uuid'), "aid": proxy.get('alterId', 0),
                                "scy": proxy.get('cipher', 'auto'), "net": proxy.get('network', 'tcp'),
                                "type": proxy.get('headerType', 'none'), # v2rayN MTP 兼容性
                                "host": proxy.get('host', proxy.get('ws-opts', {}).get('headers', {}).get('Host', '')),
                                "path": proxy.get('path', proxy.get('ws-opts', {}).get('path', '')),
                                "tls": "tls" if proxy.get('tls') else ""
                            }
                            if not all([vmess_dict["add"], vmess_dict["port"], vmess_dict["id"]]):
                                print(f"警告: [{source_url}] Vmess代理缺少必要字段 (server, port, uuid): {proxy.get('name')}")
                                continue
                            vmess_str = json.dumps(vmess_dict, sort_keys=True)
                            node_str = f"vmess://{base64.urlsafe_b64encode(vmess_str.encode()).decode().rstrip('=')}"
                            nodes.add(node_str)
                        elif node_type == 'vless':
                            # ... (VLESS和其他协议的转换逻辑，与您提供的版本类似，确保字段检查)
                            uuid = proxy.get('uuid')
                            server = proxy.get('server')
                            port = proxy.get('port')
                            if not all([uuid, server, port]):
                                print(f"警告: [{source_url}] Vless代理缺少必要字段 (uuid, server, port): {proxy.get('name')}")
                                continue
                            params = {
                                "encryption": proxy.get('encryption', 'none'),
                                "security": 'tls' if proxy.get('tls') else 'none',
                                "sni": proxy.get('sni', proxy.get('serverName', '')), # 兼容 serverName
                                "fp": proxy.get('fingerprint', proxy.get('client-fingerprint', '')), # 兼容 fingerprint
                                "type": proxy.get('network', 'tcp'),
                                "host": proxy.get('host', proxy.get('ws-opts', {}).get('headers', {}).get('Host', '')),
                                "path": proxy.get('path', proxy.get('ws-opts', {}).get('path', '')),
                                "flow": proxy.get('flow', '')
                            }
                            query_string = "&".join([f"{k}={v}" for k, v in params.items() if v]) # 只添加有值的参数
                            node_str = f"vless://{uuid}@{server}:{port}?{query_string}#{proxy.get('name', 'unnamed')}"
                            nodes.add(node_str)
                        elif node_type == 'trojan':
                            password = proxy.get('password')
                            server = proxy.get('server')
                            port = proxy.get('port')
                            if not all([password, server, port]):
                                print(f"警告: [{source_url}] Trojan代理缺少必要字段 (password, server, port): {proxy.get('name')}")
                                continue
                            params = {
                                "sni": proxy.get('sni', proxy.get('serverName', '')),
                                "security": 'tls' if proxy.get('tls', True) else 'none', # Trojan默认TLS
                                # 可添加更多Trojan参数如 "type", "path", "host" 等
                            }
                            query_string = "&".join([f"{k}={v}" for k, v in params.items() if v])
                            node_str = f"trojan://{password}@{server}:{port}?{query_string}#{proxy.get('name', 'unnamed')}"
                            nodes.add(node_str)
                        elif node_type == 'ss':
                            method = proxy.get('cipher')
                            password = proxy.get('password')
                            server = proxy.get('server')
                            port = proxy.get('port')
                            if not all([method, password, server, port]):
                                print(f"警告: [{source_url}] SS代理缺少必要字段 (cipher, password, server, port): {proxy.get('name')}")
                                continue
                            # SS URI: ss://method:password@server:port#name
                            # Base64 part for SS URI is method:password
                            auth_str = base64.urlsafe_b64encode(f"{method}:{password}".encode()).decode().rstrip('=')
                            node_str = f"ss://{auth_str}@{server}:{port}#{proxy.get('name', 'unnamed')}"
                            nodes.add(node_str)
                        elif node_type == 'hysteria2':
                            auth = proxy.get('auth', proxy.get('password')) # 兼容 auth 和 password
                            server = proxy.get('server')
                            port = proxy.get('port')
                            if not all([auth, server, port]):
                                print(f"警告: [{source_url}] Hysteria2代理缺少必要字段 (auth/password, server, port): {proxy.get('name')}")
                                continue
                            params = {
                                "sni": proxy.get('sni', proxy.get('serverName', '')),
                                "insecure": '1' if proxy.get('skip-cert-verify', False) else '',
                                # 可添加更多 Hysteria2 参数
                            }
                            query_string = "&".join([f"{k}={v}" for k, v in params.items() if v])
                            node_str = f"hysteria2://{auth}@{server}:{port}?{query_string}#{proxy.get('name', 'unnamed')}"
                            nodes.add(node_str)
                        # else:
                        #     print(f"DEBUG: [{source_url}] YAML中不支持的代理类型: {node_type} for proxy {proxy.get('name')}")
                    except Exception as e_proxy:
                        print(f"错误: [{source_url}] 处理YAML代理 {proxy.get('name', 'N/A')} (类型 {node_type}) 失败: {e_proxy}")
            else:
                print(f"DEBUG: [{source_url}] YAML文件未找到 'proxies' 列表或格式不正确。Data type: {type(data)}")
        except yaml.YAMLError as e_yaml:
            print(f"错误: [{source_url}] YAML解析失败: {e_yaml}")
        except Exception as e_general_yaml:
            print(f"错误: [{source_url}] 处理YAML时发生未知错误: {e_general_yaml}")

    else:  # 默认按纯文本处理 (plain)
        for line_num, line in enumerate(content.splitlines()):
            line = line.strip()
            if any(line.startswith(proto) for proto in PROTOCOLS):
                nodes.add(line)
        # print(f"DEBUG: [{source_url}] 普通文本直接提取到 {len(nodes)} 个节点")
    return list(nodes)

def fetch_and_extract_nodes(url, retries=3, timeout=25, is_sub_link=False):
    """获取URL内容并提取节点，处理不同内容类型和子链接"""
    print(f"INFO: 开始处理 {'子链接' if is_sub_link else '主URL'}: {url}")
    extracted_nodes_from_this_url = set()

    for attempt in range(retries):
        try:
            response = requests.get(url, timeout=timeout, headers={'User-Agent': 'Mozilla/5.0'})
            response.raise_for_status()
            content = response.text
            content_type_header = response.headers.get('Content-Type', '').lower()
            print(f"DEBUG: [{url}] 状态码: {response.status_code}, Content-Type: {content_type_header}")

            # 优先处理YAML (基于扩展名或Content-Type)
            if url.endswith(('.yaml', '.yml')):
                print(f"INFO: [{url}] 判断为YAML (基于扩展名)")
                extracted_nodes_from_this_url.update(extract_nodes_from_content(content, 'yaml', source_url=url))
            elif 'yaml' in content_type_header or 'x-yaml' in content_type_header:
                print(f"INFO: [{url}] 判断为YAML (基于Content-Type)")
                extracted_nodes_from_this_url.update(extract_nodes_from_content(content, 'yaml', source_url=url))
            # 处理Base64编码的文本
            # 改进Base64检测：检查是否主要由Base64字符组成，并且长度合理
            elif 'text/plain' in content_type_header and re.fullmatch(r'[A-Za-z0-9+/=\s\r\n]+', content.strip()) and len(content.strip()) > 20:
                # 进一步确认是否可能是Base64 (尝试解码一小部分或者查找协议头)
                is_likely_base64 = False
                try:
                    # Try decoding a small part or the whole if not too large
                    sample_decoded = base64.b64decode(content.strip().splitlines()[0][:200]).decode('utf-8', errors='ignore')
                    if any(proto in sample_decoded for proto in PROTOCOLS):
                        is_likely_base64 = True
                except:
                    pass
                
                if is_likely_base64:
                    print(f"INFO: [{url}] 判断为Base64编码文本 (基于text/plain和内容嗅探)")
                    extracted_nodes_from_this_url.update(extract_nodes_from_content(content.strip(), 'base64', source_url=url))
                else: # 如果不是Base64，则作为普通文本节点处理
                    print(f"INFO: [{url}] 判断为普通文本 (text/plain但非Base64)")
                    extracted_nodes_from_this_url.update(extract_nodes_from_content(content, 'plain', source_url=url))
            # 处理普通文本节点 (如果Content-Type是text/plain但前面未识别为Base64)
            elif 'text/plain' in content_type_header:
                print(f"INFO: [{url}] 判断为普通文本 (基于text/plain)")
                extracted_nodes_from_this_url.update(extract_nodes_from_content(content, 'plain', source_url=url))
            
            # 如果以上方式都没有提取到节点，并且不是YAML文件本身，则尝试提取子链接
            # 这个逻辑主要针对 igdux.top.txt 这类索引文件
            if not extracted_nodes_from_this_url and not url.endswith(('.yaml', '.yml')):
                print(f"INFO: [{url}] 未直接提取到节点，尝试作为链接列表解析")
                # 改进的链接提取，避免误提取非URL的部分，并处理相对路径 (虽然本例中都是绝对)
                # links = re.findall(r'https?://[^\s\'"<>]+', content)
                # 更严格的正则，只匹配看起来像订阅链接或常见节点的文本行
                potential_links = []
                for line_content in content.splitlines():
                    line_content = line_content.strip()
                    # 匹配完整的URL
                    matches = re.findall(r'https?://[a-zA-Z0-9\-\.]+\.[a-zA-Z]{2,}(?:/[^\s\'"<>]*)?', line_content)
                    potential_links.extend(matches)
                    # 如果行本身看起来像一个节点，也加入 (虽然这里主要目的是提取URL)
                    # if any(line_content.startswith(proto) for proto in PROTOCOLS):
                    #     extracted_nodes_from_this_url.add(line_content)


                links = list(set(potential_links)) # 去重
                
                if links:
                    print(f"INFO: [{url}] 提取到 {len(links)} 个潜在子链接: {links[:5]}...") #只显示前5个
                    for i, link in enumerate(links):
                        # 避免爬取已知非订阅链接的域，例如github.com本身除非是raw内容
                        if "github.com" in link and not ("raw.githubusercontent.com" in link or "/raw/" in link):
                            print(f"DEBUG: [{url}] 跳过非raw GitHub链接: {link}")
                            continue
                        # 简单过滤一些明显不是订阅链接的常见文件扩展名
                        if link.lower().endswith(('.png', '.jpg', '.gif', '.zip', '.exe', '.pdf', '.md')):
                             print(f"DEBUG: [{url}] 跳过常见非订阅文件类型: {link}")
                             continue

                        print(f"INFO: [{url}] 开始处理子链接 {i+1}/{len(links)}: {link}")
                        # 对子链接递归调用本函数进行处理
                        extracted_nodes_from_this_url.update(fetch_and_extract_nodes(link, retries, timeout, is_sub_link=True))
                else:
                    print(f"INFO: [{url}] 作为链接列表解析时未找到子链接。")
            
            break # 成功获取并处理了内容，跳出重试循环
        except requests.exceptions.RequestException as e:
            print(f"错误: [{url}] 尝试 {attempt+1}/{retries} 失败: {e}")
            if attempt == retries - 1:
                print(f"错误: [{url}] 所有重试均失败，无法访问或解析。")
    
    if extracted_nodes_from_this_url:
        print(f"成功: 从 {url} (及子链接) 共提取到 {len(extracted_nodes_from_this_url)} 个节点")
    else:
        print(f"提示: 从 {url} (及子链接) 未提取到任何节点")
        
    return list(extracted_nodes_from_this_url)


def save_nodes_to_file(nodes, filename="data/ji.txt"):
    """将节点保存到文件，每行一个节点"""
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    # 去重和排序
    unique_nodes = sorted(list(set(nodes)))
    with open(filename, "w", encoding="utf-8") as f:
        for node in unique_nodes:
            f.write(node + "\n")
    print(f"文件: 成功保存 {len(unique_nodes)} 个唯一节点到 {filename}")


if __name__ == "__main__":
    main_urls = [
        "https://github.com/qjlxg/TV/raw/refs/heads/main/url/igdux.top.txt",
        "https://github.com/qjlxg/aggregator/raw/refs/heads/main/data/ss.txt",
        "https://github.com/qjlxg/aggregator/raw/refs/heads/main/data/v2ray.txt",
        "https://github.com/qjlxg/aggregator/raw/refs/heads/main/data/clash.yaml",
    ]

    all_extracted_nodes = set()
    for url in main_urls:
        nodes_from_url = fetch_and_extract_nodes(url)
        if nodes_from_url:
            all_extracted_nodes.update(nodes_from_url)

    unique_nodes_list = sorted(list(all_extracted_nodes))
    print(f"\n总结: 共提取到 {len(all_extracted_nodes)} 个节点，去重后 {len(unique_nodes_list)} 个唯一节点。")
    save_nodes_to_file(unique_nodes_list)
